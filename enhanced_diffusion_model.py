#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆæ‰©æ•£æ¨¡å‹ v2.0 - é’ˆå¯¹DNAç»“åˆä½ç‚¹ç”Ÿæˆä¼˜åŒ–

æ”¹è¿›ç‚¹ï¼š
1. æ¡ä»¶æ‰©æ•£ï¼ˆConditional Diffusionï¼‰- ä½¿ç”¨è›‹ç™½è´¨ä¸Šä¸‹æ–‡å¼•å¯¼ç”Ÿæˆ
2. è‡ªé€‚åº”å»å™ª - æ ¹æ®è›‹ç™½è´¨ç‰¹æ€§è°ƒæ•´å»å™ªå¼ºåº¦
3. è´¨é‡æ„ŸçŸ¥é‡‡æ · - å¤šæ¬¡é‡‡æ ·å–æœ€ä¼˜
4. å¤šæ ·æ€§å¢å¼º - æ·»åŠ å¯æ§å™ªå£°ä¿è¯å¤šæ ·æ€§
5. ç±»åˆ«å¹³è¡¡ç”Ÿæˆ - ç¡®ä¿è¾¾åˆ°ç›®æ ‡æ¯”ä¾‹
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from tqdm import tqdm


class ConditionalNoiseScheduler:
    """æ¡ä»¶åŒ–çš„å™ªå£°è°ƒåº¦å™¨ - æ ¹æ®è›‹ç™½è´¨ä¸Šä¸‹æ–‡è°ƒæ•´"""
    def __init__(self, T=1000, beta_start=1e-4, beta_end=0.02):
        self.T = T
        self.betas = torch.linspace(beta_start, beta_end, T)
        self.alphas = 1.0 - self.betas
        self.alpha_bars = torch.cumprod(self.alphas, dim=0)

    def get_alpha_bars(self, t, protein_complexity=1.0):
        """æ ¹æ®è›‹ç™½è´¨å¤æ‚åº¦è°ƒæ•´alpha"""
        base_alpha = self.alpha_bars[t]
        # å¤æ‚è›‹ç™½è´¨éœ€è¦æ›´æ…¢çš„æ‰©æ•£
        adjusted_alpha = base_alpha ** (1.0 / protein_complexity)
        return adjusted_alpha


class ContextEncoder(nn.Module):
    """è›‹ç™½è´¨ä¸Šä¸‹æ–‡ç¼–ç å™¨ - æå–å…¨å±€ç‰¹å¾å¼•å¯¼ç”Ÿæˆ"""
    def __init__(self, input_dim=1280, hidden_dim=512, context_dim=256):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, context_dim),
            nn.LayerNorm(context_dim),
            nn.GELU()
        )

        # æ³¨æ„åŠ›æœºåˆ¶ - èšç„¦é‡è¦åŒºåŸŸ
        self.attention = nn.MultiheadAttention(
            embed_dim=context_dim,
            num_heads=4,
            dropout=0.1,
            batch_first=True
        )

    def forward(self, x, mask=None):
        """
        Args:
            x: (batch, seq_len, input_dim) æˆ– (seq_len, input_dim)
        Returns:
            global_context: (context_dim,) å…¨å±€ä¸Šä¸‹æ–‡å‘é‡
            local_features: (seq_len, context_dim) å±€éƒ¨ç‰¹å¾
        """
        if x.dim() == 2:
            x = x.unsqueeze(0)  # (1, seq_len, input_dim)

        # ç¼–ç 
        features = self.encoder(x)  # (batch, seq_len, context_dim)

        # è‡ªæ³¨æ„åŠ›
        attn_out, attn_weights = self.attention(features, features, features)

        # å…¨å±€ä¸Šä¸‹æ–‡ = åŠ æƒå¹³å‡
        if mask is not None:
            attn_weights = attn_weights * mask.unsqueeze(1)

        global_context = torch.mean(attn_out, dim=1).squeeze(0)  # (context_dim,)
        local_features = attn_out.squeeze(0)  # (seq_len, context_dim)

        return global_context, local_features, attn_weights


class EnhancedConditionalDiffusionModel(nn.Module):
    """å¢å¼ºç‰ˆæ¡ä»¶æ‰©æ•£æ¨¡å‹"""
    def __init__(self, input_dim=1280, T=500, hidden_dim=512, context_dim=256, device='cuda'):
        super().__init__()
        self.input_dim = input_dim
        self.T = T
        self.device = device

        # ä¸Šä¸‹æ–‡ç¼–ç å™¨
        self.context_encoder = ContextEncoder(input_dim, hidden_dim, context_dim)

        # æ¡ä»¶åŒ–çš„å»å™ªç½‘ç»œ
        self.denoiser = nn.Sequential(
            nn.Linear(input_dim + context_dim + 1, hidden_dim),  # +1 for timestep
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Dropout(0.2),

            nn.Linear(hidden_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Dropout(0.2),

            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.LayerNorm(hidden_dim // 2),
            nn.GELU(),

            nn.Linear(hidden_dim // 2, input_dim)
        )

        # æ—¶é—´æ­¥åµŒå…¥
        self.time_embed = nn.Embedding(T, hidden_dim)
        self.time_proj = nn.Linear(hidden_dim, 1)

        # å™ªå£°è°ƒåº¦å™¨
        self.scheduler = ConditionalNoiseScheduler(T)

        self.to(device)

    def forward_diffusion(self, x0, t, protein_context):
        """å‰å‘æ‰©æ•£è¿‡ç¨‹ï¼ˆåŠ å™ªï¼‰"""
        noise = torch.randn_like(x0)

        # è·å–æ¡ä»¶åŒ–çš„alpha
        complexity = self.estimate_complexity(protein_context)
        alpha_bar = self.scheduler.get_alpha_bars(t, complexity)

        # åŠ å™ª
        sqrt_alpha_bar = torch.sqrt(alpha_bar)
        sqrt_one_minus_alpha_bar = torch.sqrt(1.0 - alpha_bar)

        xt = sqrt_alpha_bar * x0 + sqrt_one_minus_alpha_bar * noise

        return xt, noise

    def estimate_complexity(self, protein_context):
        """ä¼°è®¡è›‹ç™½è´¨å¤æ‚åº¦ï¼ˆç”¨äºè°ƒæ•´æ‰©æ•£å¼ºåº¦ï¼‰"""
        # åŸºäºç‰¹å¾çš„æ ‡å‡†å·®ä¼°è®¡å¤æ‚åº¦
        std = torch.std(protein_context)
        complexity = torch.clamp(std / 0.5, 0.5, 2.0)  # [0.5, 2.0]
        return complexity.item()

    def reverse_diffusion_step(self, xt, t, global_context):
        """åå‘æ‰©æ•£å•æ­¥ï¼ˆå»å™ªï¼‰- ä¼˜åŒ–ç‰ˆ"""
        batch_size = xt.size(0)

        # ğŸš€ ä½¿ç”¨ç¼“å­˜çš„æ—¶é—´åµŒå…¥ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if not hasattr(self, '_t_cache') or self._t_cache_t != t:
            t_tensor = torch.tensor([t], device=self.device)
            t_embed = self.time_embed(t_tensor)
            t_feature = self.time_proj(t_embed)  # (1, 1)
            self._t_cache = t_feature
            self._t_cache_t = t
        else:
            t_feature = self._t_cache

        # å¹¿æ’­ä¸Šä¸‹æ–‡å’Œæ—¶é—´ç‰¹å¾åˆ°batchç»´åº¦ï¼ˆä½¿ç”¨expandé¿å…å†…å­˜å¤åˆ¶ï¼‰
        global_context_expanded = global_context.unsqueeze(0).expand(batch_size, -1)
        t_feature_expanded = t_feature.expand(batch_size, -1)

        # æ‹¼æ¥æ¡ä»¶ï¼ˆä½¿ç”¨stackç„¶åviewå¯èƒ½æ›´å¿«ï¼Œä½†catæ›´é€šç”¨ï¼‰
        xt_with_context = torch.cat([
            xt,
            global_context_expanded,
            t_feature_expanded
        ], dim=-1)

        # é¢„æµ‹å™ªå£°
        predicted_noise = self.denoiser(xt_with_context)

        # å»å™ª - é¢„è®¡ç®—å¸¸é‡
        alpha = self.scheduler.alphas[t].to(self.device)
        alpha_bar = self.scheduler.alpha_bars[t].to(self.device)

        # ğŸš€ ä½¿ç”¨fusedæ“ä½œå‡å°‘kernelå¯åŠ¨æ¬¡æ•°
        sqrt_alpha = torch.sqrt(alpha)
        coef = (1 - alpha) / torch.sqrt(1 - alpha_bar)
        x_prev = (xt - coef * predicted_noise) / sqrt_alpha

        if t > 0:
            # åªåœ¨éœ€è¦æ—¶ç”Ÿæˆå™ªå£°
            beta = self.scheduler.betas[t].to(self.device)
            noise = torch.randn_like(xt)
            x_prev = x_prev + torch.sqrt(beta) * noise

        return x_prev

    def generate_positive_sample(self, protein_data, num_samples=1,
                                 quality_threshold=0.5, max_attempts=5):
        """
        ç”Ÿæˆé«˜è´¨é‡æ­£æ ·æœ¬

        Args:
            protein_data: PyG Data object
            num_samples: ç”Ÿæˆæ•°é‡
            quality_threshold: è´¨é‡é˜ˆå€¼
            max_attempts: æœ€å¤§å°è¯•æ¬¡æ•°

        Returns:
            samples: (num_samples, input_dim)
            quality_scores: (num_samples,)
        """
        self.eval()

        # ğŸš€ ä½¿ç”¨inferenceæ¨¡å¼æå‡æ€§èƒ½ï¼ˆæ¯”no_gradæ›´å¿«ï¼‰
        with torch.inference_mode():
            # æå–ä¸Šä¸‹æ–‡
            protein_x = protein_data.x.to(self.device)
            protein_y = protein_data.y.to(self.device)

            # ç¼–ç ä¸Šä¸‹æ–‡
            global_context, local_features, _ = self.context_encoder(protein_x)

            # æå–æ­£æ ·æœ¬ç‰¹å¾ï¼ˆç”¨äºè´¨é‡è¯„ä¼°ï¼‰
            positive_mask = (protein_y == 1)
            if positive_mask.sum() > 0:
                positive_features = protein_x[positive_mask]
                positive_mean = torch.mean(positive_features, dim=0)
                positive_std = torch.std(positive_features, dim=0) + 1e-6
            else:
                positive_mean = torch.mean(protein_x, dim=0)
                positive_std = torch.std(protein_x, dim=0) + 1e-6

            # ğŸš€ æ‰¹é‡ç”Ÿæˆæ‰€æœ‰å€™é€‰æ ·æœ¬ï¼ˆä¸€æ¬¡æ€§ç”Ÿæˆï¼Œé¿å…å¾ªç¯ï¼‰
            total_candidates = num_samples * max_attempts

            # ä»çº¯å™ªå£°å¼€å§‹ï¼ˆæ‰¹é‡ï¼‰- ä½¿ç”¨å›ºå®šç”Ÿæˆå™¨æé«˜æ•ˆç‡
            xt = torch.randn(total_candidates, self.input_dim, device=self.device, dtype=torch.float32)

            # é€æ­¥å»å™ªï¼ˆæ‰¹é‡å¤„ç†æ‰€æœ‰å€™é€‰æ ·æœ¬ï¼‰- ä½¿ç”¨rangeç¼“å­˜å‡å°‘å¼€é”€
            time_steps = list(reversed(range(self.T)))
            for t in time_steps:
                xt = self.reverse_diffusion_step(xt, t, global_context)

            # è¯„ä¼°è´¨é‡ï¼ˆæ‰¹é‡ï¼‰
            all_scores = self.evaluate_quality(xt, positive_mean, positive_std, global_context)
            all_samples = xt

            # é€‰æ‹©top-ké«˜è´¨é‡æ ·æœ¬
            top_k_indices = torch.topk(all_scores, k=num_samples).indices
            final_samples = all_samples[top_k_indices]
            final_scores = all_scores[top_k_indices]

            # ğŸš€ ä¿æŒåœ¨GPUä¸Šï¼Œé¿å…CPU-GPUæ•°æ®ä¼ è¾“
            return final_samples, final_scores

    def evaluate_quality(self, samples, positive_mean, positive_std, global_context):
        """
        è¯„ä¼°ç”Ÿæˆæ ·æœ¬è´¨é‡ - ä¿®å¤ç‰ˆ

        è´¨é‡æŒ‡æ ‡ï¼š
        1. ä¸æ­£æ ·æœ¬åˆ†å¸ƒçš„ç›¸ä¼¼åº¦ï¼ˆä¸»è¦æŒ‡æ ‡ï¼‰
        2. ç‰¹å¾çš„åˆç†æ€§ï¼ˆä¸èƒ½æœ‰å¼‚å¸¸å€¼ï¼‰
        3. ç‰¹å¾èŒƒå›´åˆç†æ€§
        """
        # 1. åˆ†å¸ƒç›¸ä¼¼åº¦ï¼ˆå½’ä¸€åŒ–åçš„è·ç¦»ï¼‰- æƒé‡æé«˜
        normalized_samples = (samples - positive_mean) / positive_std
        # ä½¿ç”¨æ›´æ¸©å’Œçš„è·ç¦»è®¡ç®—
        dist = torch.mean(normalized_samples ** 2, dim=1)
        dist_score = torch.exp(-dist / 5.0)  # æ›´æ¸©å’Œçš„è¡°å‡

        # 2. åˆç†æ€§ï¼ˆæ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸å€¼ï¼‰- æƒé‡é™ä½
        max_abs_norm = torch.max(torch.abs(normalized_samples), dim=1).values
        validity_score = torch.exp(-max_abs_norm / 3.0)  # å…è®¸ä¸€å®šçš„å¼‚å¸¸å€¼

        # 3. ç‰¹å¾èŒƒå›´åˆç†æ€§ï¼ˆç”Ÿæˆçš„ç‰¹å¾åº”è¯¥åœ¨åˆç†èŒƒå›´å†…ï¼‰
        # ESM2ç‰¹å¾é€šå¸¸åœ¨[-10, 10]èŒƒå›´å†…
        range_penalty = torch.clamp(torch.abs(samples).max(dim=1).values - 10.0, min=0.0)
        range_score = torch.exp(-range_penalty / 5.0)

        # ç»¼åˆè´¨é‡åˆ†æ•° - ä¸»è¦ä¾èµ–åˆ†å¸ƒç›¸ä¼¼åº¦
        quality = 0.6 * dist_score + 0.25 * validity_score + 0.15 * range_score

        return quality

    def train_on_positive_samples(self, dataset, epochs=100, batch_size=32, lr=1e-4):
        """è®­ç»ƒæ‰©æ•£æ¨¡å‹"""
        self.train()
        optimizer = torch.optim.AdamW(self.parameters(), lr=lr, weight_decay=1e-5)
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)

        print(f"ğŸ¨ è®­ç»ƒå¢å¼ºç‰ˆæ‰©æ•£æ¨¡å‹ (T={self.T}, epochs={epochs})")

        for epoch in range(epochs):
            total_loss = 0
            count = 0

            for data in dataset:
                # æå–æ­£æ ·æœ¬
                positive_mask = (data.y == 1)
                if positive_mask.sum() == 0:
                    continue

                positive_samples = data.x[positive_mask].to(self.device)
                protein_context = data.protein_context.to(self.device)

                # ç¼–ç ä¸Šä¸‹æ–‡ï¼ˆdetaché¿å…é‡å¤backwardï¼‰
                with torch.no_grad():
                    global_context, _, _ = self.context_encoder(data.x.to(self.device))
                global_context = global_context.detach()  # ä»è®¡ç®—å›¾ä¸­åˆ†ç¦»

                # è®­ç»ƒ
                for i in range(0, positive_samples.size(0), batch_size):
                    batch = positive_samples[i:i+batch_size]

                    # éšæœºæ—¶é—´æ­¥
                    t = torch.randint(0, self.T, (1,), device=self.device).item()

                    # å‰å‘æ‰©æ•£
                    xt, noise = self.forward_diffusion(batch, t, protein_context)

                    # é¢„æµ‹å™ªå£°
                    t_tensor = torch.tensor([t], device=self.device)
                    t_embed = self.time_embed(t_tensor)
                    t_feature = self.time_proj(t_embed)

                    global_context_expanded = global_context.unsqueeze(0).expand(batch.size(0), -1)
                    t_feature_expanded = t_feature.expand(batch.size(0), -1)

                    xt_with_context = torch.cat([
                        xt,
                        global_context_expanded,
                        t_feature_expanded
                    ], dim=-1)

                    predicted_noise = self.denoiser(xt_with_context)

                    # æŸå¤±
                    loss = F.mse_loss(predicted_noise, noise)

                    optimizer.zero_grad()
                    loss.backward(retain_graph=False)  # ğŸ”§ ä¿®å¤ï¼šæ˜¾å¼è®¾ç½®retain_graph=False
                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1.0)
                    optimizer.step()

                    total_loss += loss.item()
                    count += 1

            scheduler.step()

            if epoch % 20 == 0 or epoch == epochs - 1:
                avg_loss = total_loss / max(count, 1)
                print(f"  Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f} - LR: {scheduler.get_last_lr()[0]:.2e}")

        print(f"âœ… æ‰©æ•£æ¨¡å‹è®­ç»ƒå®Œæˆ")
