#!/usr/bin/env python3
"""
æ­¥éª¤7: é›†æˆåˆ°ä¸»Pipeline
å°†è®­ç»ƒå¥½çš„è¾¹é¢„æµ‹å™¨é›†æˆåˆ°ä¸»PPIé¢„æµ‹Pipelineä¸­
"""
import os
import sys
import json
import numpy as np
import torch
from tqdm import tqdm

# å¯¼å…¥è¾¹é¢„æµ‹å™¨æ¨¡å‹
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, parent_dir)
from edge_predictor_augmentation import ImprovedEdgePredictor

# å¯¼å…¥é…ç½®
current_dir = os.path.dirname(os.path.abspath(__file__))
import importlib.util
config_path = os.path.join(current_dir, "ppi_config.py")
spec = importlib.util.spec_from_file_location("ppi_config", config_path)
config = importlib.util.module_from_spec(spec)
spec.loader.exec_module(config)

FEATURE_DIM = config.FEATURE_DIM
DEVICE = config.DEVICE
PPI_PROCESSED_DIR = config.PPI_PROCESSED_DIR


class PPIPredictionPipeline:
    """å®Œæ•´çš„PPIé¢„æµ‹Pipeline"""

    def __init__(self, model_path=None):
        """
        åˆå§‹åŒ–Pipeline

        å‚æ•°:
            model_path: è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
        """
        self.device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")
        print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {self.device}")

        # é»˜è®¤æ¨¡å‹è·¯å¾„
        if model_path is None:
            model_path = os.path.join(current_dir, "models", "edge_predictor_best.pth")

        # åŠ è½½æ¨¡å‹ï¼ˆhidden_diméœ€è¦ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        hidden_dim = getattr(config, 'HIDDEN_DIM', 1024)
        self.model = ImprovedEdgePredictor(input_dim=FEATURE_DIM, hidden_dim=hidden_dim).to(self.device)

        if os.path.exists(model_path):
            checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.eval()
            print(f"âœ… æ¨¡å‹å·²åŠ è½½: {model_path}")
            print(f"   è®­ç»ƒæ—¶æœ€ä½³AUC: {checkpoint.get('best_auc', 0.0):.4f}")
        else:
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

        # åŠ è½½è›‹ç™½è´¨ç‰¹å¾å’Œæ˜ å°„
        self.features = None
        self.protein_to_idx = None
        self.idx_to_protein = None
        self._load_features()

    def _load_features(self):
        """åŠ è½½ESM2ç‰¹å¾å’Œè›‹ç™½è´¨æ˜ å°„"""
        print("\nğŸ“Š åŠ è½½è›‹ç™½è´¨ç‰¹å¾...")

        features_file = os.path.join(PPI_PROCESSED_DIR, "features.npy")
        mapping_file = os.path.join(PPI_PROCESSED_DIR, "protein_mapping.json")

        if not os.path.exists(features_file):
            raise FileNotFoundError(f"ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {features_file}")

        # åŠ è½½ç‰¹å¾
        self.features = np.load(features_file)
        print(f"âœ… ç‰¹å¾å·²åŠ è½½: {self.features.shape}")

        # åŠ è½½æ˜ å°„
        with open(mapping_file, 'r') as f:
            mapping = json.load(f)
            self.protein_to_idx = mapping['protein_to_idx']
            self.idx_to_protein = {int(k): v for k, v in mapping['idx_to_protein'].items()}

        print(f"âœ… è›‹ç™½è´¨æ˜ å°„å·²åŠ è½½: {len(self.protein_to_idx)} ä¸ªè›‹ç™½è´¨")

    def predict_interaction(self, protein1, protein2):
        """
        é¢„æµ‹ä¸¤ä¸ªè›‹ç™½è´¨ä¹‹é—´æ˜¯å¦å­˜åœ¨ç›¸äº’ä½œç”¨

        å‚æ•°:
            protein1: è›‹ç™½è´¨1çš„ID (STRING ID)
            protein2: è›‹ç™½è´¨2çš„ID (STRING ID)

        è¿”å›:
            score: ç›¸äº’ä½œç”¨æ¦‚ç‡ (0-1)
        """
        # æ£€æŸ¥è›‹ç™½è´¨æ˜¯å¦åœ¨æ•°æ®åº“ä¸­
        if protein1 not in self.protein_to_idx:
            raise ValueError(f"è›‹ç™½è´¨ {protein1} ä¸åœ¨æ•°æ®åº“ä¸­")
        if protein2 not in self.protein_to_idx:
            raise ValueError(f"è›‹ç™½è´¨ {protein2} ä¸åœ¨æ•°æ®åº“ä¸­")

        # è·å–ç‰¹å¾ç´¢å¼•
        idx1 = self.protein_to_idx[protein1]
        idx2 = self.protein_to_idx[protein2]

        # æå–ç‰¹å¾
        feat1 = torch.tensor(self.features[idx1], dtype=torch.float32).unsqueeze(0).to(self.device)
        feat2 = torch.tensor(self.features[idx2], dtype=torch.float32).unsqueeze(0).to(self.device)

        # é¢„æµ‹
        with torch.no_grad():
            score = self.model(feat1, feat2).item()

        return score

    def predict_interactions_batch(self, protein_pairs, batch_size=512):
        """
        æ‰¹é‡é¢„æµ‹å¤šä¸ªè›‹ç™½è´¨å¯¹ä¹‹é—´çš„ç›¸äº’ä½œç”¨

        å‚æ•°:
            protein_pairs: è›‹ç™½è´¨å¯¹åˆ—è¡¨ [(protein1, protein2), ...]
            batch_size: æ‰¹å¤„ç†å¤§å°

        è¿”å›:
            scores: ç›¸äº’ä½œç”¨æ¦‚ç‡æ•°ç»„
        """
        print(f"\nğŸ”® æ‰¹é‡é¢„æµ‹ {len(protein_pairs):,} ä¸ªè›‹ç™½è´¨å¯¹...")

        all_scores = []

        for i in tqdm(range(0, len(protein_pairs), batch_size), desc="é¢„æµ‹"):
            batch_pairs = protein_pairs[i:i+batch_size]

            # å‡†å¤‡æ‰¹æ¬¡ç‰¹å¾
            src_feats = []
            dst_feats = []

            for p1, p2 in batch_pairs:
                if p1 not in self.protein_to_idx or p2 not in self.protein_to_idx:
                    # è·³è¿‡ä¸åœ¨æ•°æ®åº“ä¸­çš„è›‹ç™½è´¨å¯¹
                    all_scores.append(0.0)
                    continue

                idx1 = self.protein_to_idx[p1]
                idx2 = self.protein_to_idx[p2]

                src_feats.append(self.features[idx1])
                dst_feats.append(self.features[idx2])

            if len(src_feats) == 0:
                continue

            # è½¬æ¢ä¸ºå¼ é‡
            src_feats = torch.tensor(np.array(src_feats), dtype=torch.float32).to(self.device)
            dst_feats = torch.tensor(np.array(dst_feats), dtype=torch.float32).to(self.device)

            # é¢„æµ‹
            with torch.no_grad():
                batch_scores = self.model(src_feats, dst_feats).squeeze().cpu().numpy()  # [batch, 1] -> [batch]

            all_scores.extend(batch_scores)

        return np.array(all_scores)

    def predict_for_protein(self, protein_id, top_k=100, threshold=0.5):
        """
        é¢„æµ‹ç»™å®šè›‹ç™½è´¨ä¸æ‰€æœ‰å…¶ä»–è›‹ç™½è´¨çš„ç›¸äº’ä½œç”¨

        å‚æ•°:
            protein_id: ç›®æ ‡è›‹ç™½è´¨ID
            top_k: è¿”å›å‰kä¸ªæœ€å¯èƒ½çš„ç›¸äº’ä½œç”¨
            threshold: åˆ†æ•°é˜ˆå€¼ï¼Œåªè¿”å›åˆ†æ•°é«˜äºæ­¤å€¼çš„ç›¸äº’ä½œç”¨

        è¿”å›:
            predictions: [(partner_protein, score), ...] æŒ‰åˆ†æ•°é™åºæ’åˆ—
        """
        print(f"\nğŸ” é¢„æµ‹è›‹ç™½è´¨ {protein_id} çš„æ½œåœ¨ç›¸äº’ä½œç”¨ä¼™ä¼´...")

        if protein_id not in self.protein_to_idx:
            raise ValueError(f"è›‹ç™½è´¨ {protein_id} ä¸åœ¨æ•°æ®åº“ä¸­")

        idx = self.protein_to_idx[protein_id]
        feat = self.features[idx]

        # ä¸æ‰€æœ‰å…¶ä»–è›‹ç™½è´¨è¿›è¡Œé¢„æµ‹
        all_scores = []
        all_proteins = []

        batch_size = 512
        num_proteins = len(self.idx_to_protein)

        for i in tqdm(range(0, num_proteins, batch_size), desc="é¢„æµ‹"):
            batch_indices = list(range(i, min(i + batch_size, num_proteins)))

            # è·³è¿‡è‡ªå·±
            batch_indices = [idx2 for idx2 in batch_indices if idx2 != idx]

            if len(batch_indices) == 0:
                continue

            # å‡†å¤‡æ‰¹æ¬¡
            src_feats = np.tile(feat, (len(batch_indices), 1))
            dst_feats = self.features[batch_indices]

            # è½¬æ¢ä¸ºå¼ é‡
            src_feats = torch.tensor(src_feats, dtype=torch.float32).to(self.device)
            dst_feats = torch.tensor(dst_feats, dtype=torch.float32).to(self.device)

            # é¢„æµ‹
            with torch.no_grad():
                batch_scores = self.model(src_feats, dst_feats).squeeze().cpu().numpy()  # [batch, 1] -> [batch]

            all_scores.extend(batch_scores)
            all_proteins.extend([self.idx_to_protein[idx2] for idx2 in batch_indices])

        # è¿‡æ»¤å’Œæ’åº
        predictions = [(p, s) for p, s in zip(all_proteins, all_scores) if s >= threshold]
        predictions.sort(key=lambda x: x[1], reverse=True)

        print(f"âœ… æ‰¾åˆ° {len(predictions):,} ä¸ªæ½œåœ¨ç›¸äº’ä½œç”¨ (åˆ†æ•° >= {threshold})")

        return predictions[:top_k]

    def export_model_for_production(self, output_path=None):
        """
        å¯¼å‡ºæ¨¡å‹ç”¨äºç”Ÿäº§ç¯å¢ƒ

        å‚æ•°:
            output_path: å¯¼å‡ºè·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
        """
        if output_path is None:
            output_path = os.path.join(current_dir, "models", "edge_predictor_production.pth")

        print(f"\nğŸ“¦ å¯¼å‡ºç”Ÿäº§æ¨¡å‹...")

        # ä¿å­˜æ¨¡å‹å’Œå…ƒæ•°æ®
        export_dict = {
            'model_state_dict': self.model.state_dict(),
            'feature_dim': FEATURE_DIM,
            'num_proteins': len(self.protein_to_idx),
            'device': str(self.device)
        }

        torch.save(export_dict, output_path)

        print(f"âœ… ç”Ÿäº§æ¨¡å‹å·²å¯¼å‡º: {output_path}")

        # åˆ›å»ºä½¿ç”¨è¯´æ˜
        readme_path = os.path.join(os.path.dirname(output_path), "USAGE.md")
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write("# PPIé¢„æµ‹æ¨¡å‹ä½¿ç”¨è¯´æ˜\n\n")
            f.write("## å¿«é€Ÿå¼€å§‹\n\n")
            f.write("```python\n")
            f.write("from integrate_with_pipeline import PPIPredictionPipeline\n\n")
            f.write("# åˆå§‹åŒ–Pipeline\n")
            f.write("pipeline = PPIPredictionPipeline()\n\n")
            f.write("# é¢„æµ‹å•ä¸ªè›‹ç™½è´¨å¯¹\n")
            f.write('score = pipeline.predict_interaction("ENSP00000000001", "ENSP00000000002")\n')
            f.write('print(f"ç›¸äº’ä½œç”¨æ¦‚ç‡: {score:.4f}")\n\n')
            f.write("# æ‰¹é‡é¢„æµ‹\n")
            f.write('pairs = [("ENSP00000000001", "ENSP00000000002"), ...]\n')
            f.write("scores = pipeline.predict_interactions_batch(pairs)\n\n")
            f.write("# é¢„æµ‹æŸä¸ªè›‹ç™½è´¨çš„æ‰€æœ‰æ½œåœ¨ä¼™ä¼´\n")
            f.write('partners = pipeline.predict_for_protein("ENSP00000000001", top_k=50)\n')
            f.write("```\n\n")
            f.write("## æ¨¡å‹ä¿¡æ¯\n\n")
            f.write(f"- ç‰¹å¾ç»´åº¦: {FEATURE_DIM}\n")
            f.write(f"- è›‹ç™½è´¨æ•°é‡: {len(self.protein_to_idx):,}\n")
            f.write(f"- ç‰¹å¾æå–: ESM2 (facebook/esm2_t33_650M_UR50D)\n")
            f.write(f"- æ•°æ®æ¥æº: STRING v12.0 (Homo sapiens)\n")

        print(f"âœ… ä½¿ç”¨è¯´æ˜å·²åˆ›å»º: {readme_path}")


def demo():
    """ç¤ºä¾‹ï¼šå¦‚ä½•ä½¿ç”¨Pipeline"""
    print("\n" + "=" * 70)
    print("ğŸ¯ Pipelineä½¿ç”¨ç¤ºä¾‹")
    print("=" * 70)

    # åˆå§‹åŒ–Pipeline
    pipeline = PPIPredictionPipeline()

    # åŠ è½½æµ‹è¯•æ•°æ®ä»¥è·å–ä¸€äº›ç¤ºä¾‹è›‹ç™½è´¨å¯¹
    edges_test = np.load(os.path.join(PPI_PROCESSED_DIR, "edges_test.npy"))
    labels_test = np.load(os.path.join(PPI_PROCESSED_DIR, "labels_test.npy"))

    # è·å–ä¸€äº›æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬
    pos_indices = np.where(labels_test == 1)[0][:5]
    neg_indices = np.where(labels_test == 0)[0][:5]

    print("\nğŸ“Š ç¤ºä¾‹1: é¢„æµ‹å·²çŸ¥çš„æ­£æ ·æœ¬ï¼ˆçœŸå®ç›¸äº’ä½œç”¨ï¼‰")
    print("-" * 70)
    for idx in pos_indices:
        src_idx, dst_idx = edges_test[idx]
        p1 = pipeline.idx_to_protein[src_idx]
        p2 = pipeline.idx_to_protein[dst_idx]

        score = pipeline.predict_interaction(p1, p2)
        print(f"  {p1} <-> {p2}: {score:.4f} {'âœ…' if score > 0.5 else 'âŒ'}")

    print("\nğŸ“Š ç¤ºä¾‹2: é¢„æµ‹è´Ÿæ ·æœ¬ï¼ˆæ— ç›¸äº’ä½œç”¨ï¼‰")
    print("-" * 70)
    for idx in neg_indices:
        src_idx, dst_idx = edges_test[idx]
        p1 = pipeline.idx_to_protein[src_idx]
        p2 = pipeline.idx_to_protein[dst_idx]

        score = pipeline.predict_interaction(p1, p2)
        print(f"  {p1} <-> {p2}: {score:.4f} {'âŒ' if score < 0.5 else 'âš ï¸'}")

    # ç¤ºä¾‹3: æ‰¹é‡é¢„æµ‹
    print("\nğŸ“Š ç¤ºä¾‹3: æ‰¹é‡é¢„æµ‹")
    print("-" * 70)
    sample_pairs = []
    for idx in pos_indices[:3]:
        src_idx, dst_idx = edges_test[idx]
        p1 = pipeline.idx_to_protein[src_idx]
        p2 = pipeline.idx_to_protein[dst_idx]
        sample_pairs.append((p1, p2))

    scores = pipeline.predict_interactions_batch(sample_pairs)
    for (p1, p2), score in zip(sample_pairs, scores):
        print(f"  {p1} <-> {p2}: {score:.4f}")

    # ç¤ºä¾‹4: é¢„æµ‹æŸä¸ªè›‹ç™½è´¨çš„æ½œåœ¨ä¼™ä¼´
    print("\nğŸ“Š ç¤ºä¾‹4: é¢„æµ‹è›‹ç™½è´¨çš„Top-10æ½œåœ¨ç›¸äº’ä½œç”¨ä¼™ä¼´")
    print("-" * 70)
    sample_protein = pipeline.idx_to_protein[edges_test[pos_indices[0]][0]]
    print(f"  ç›®æ ‡è›‹ç™½è´¨: {sample_protein}")

    partners = pipeline.predict_for_protein(sample_protein, top_k=10, threshold=0.5)
    for i, (partner, score) in enumerate(partners, 1):
        print(f"  {i:2d}. {partner}: {score:.4f}")

    # å¯¼å‡ºç”Ÿäº§æ¨¡å‹
    pipeline.export_model_for_production()


def main():
    print("ğŸ”— æ­¥éª¤7: é›†æˆåˆ°ä¸»Pipeline")
    print("=" * 70)

    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    model_path = os.path.join(current_dir, "models", "edge_predictor_best.pth")
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆè¿è¡Œ: python 5_train_edge_predictor.py")
        return False

    # è¿è¡Œç¤ºä¾‹
    try:
        demo()
    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹è¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

    print("\n" + "=" * 70)
    print("âœ… æ­¥éª¤7å®Œæˆ: Pipelineé›†æˆå®Œæˆ")
    print("\nğŸ“š ä½¿ç”¨æ–¹æ³•:")
    print("```python")
    print("from integrate_with_pipeline import PPIPredictionPipeline")
    print("")
    print("# åˆå§‹åŒ–")
    print("pipeline = PPIPredictionPipeline()")
    print("")
    print("# é¢„æµ‹å•ä¸ªè›‹ç™½è´¨å¯¹")
    print('score = pipeline.predict_interaction("PROTEIN1", "PROTEIN2")')
    print("")
    print("# æ‰¹é‡é¢„æµ‹")
    print("scores = pipeline.predict_interactions_batch(protein_pairs)")
    print("")
    print("# é¢„æµ‹æŸä¸ªè›‹ç™½è´¨çš„æ½œåœ¨ä¼™ä¼´")
    print('partners = pipeline.predict_for_protein("PROTEIN_ID", top_k=100)')
    print("```")

    print("\nğŸ‰ å®Œæ•´è®­ç»ƒæµç¨‹å·²å®Œæˆ!")
    print("\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print("   â€¢ è®­ç»ƒå¥½çš„æ¨¡å‹: models/edge_predictor_best.pth")
    print("   â€¢ ç”Ÿäº§æ¨¡å‹: models/edge_predictor_production.pth")
    print("   â€¢ è¯„ä¼°ç»“æœ: results/")
    print("   â€¢ ä½¿ç”¨è¯´æ˜: models/USAGE.md")

    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
